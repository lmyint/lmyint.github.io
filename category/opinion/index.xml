<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Opinion | Leslie Myint</title>
    <link>/category/opinion/</link>
      <atom:link href="/category/opinion/index.xml" rel="self" type="application/rss+xml" />
    <description>Opinion</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© 2022</copyright><lastBuildDate>Wed, 16 Aug 2017 00:46:20 +0000</lastBuildDate>
    <image>
      <url>/images/icon_hu43d5dce61d5c3d4d64899382e97bf121_37040_512x512_fill_lanczos_center_2.png</url>
      <title>Opinion</title>
      <link>/category/opinion/</link>
    </image>
    
    <item>
      <title>Fight every battle everywhere: this is science</title>
      <link>/post/fight-every-battle/</link>
      <pubDate>Wed, 16 Aug 2017 00:46:20 +0000</pubDate>
      <guid>/post/fight-every-battle/</guid>
      <description>&lt;p&gt;I love Game of Thrones. I particularly liked this mini-speech from Petyr Baelish earlier in Season 7:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Don’t fight in the North or the South. Fight every battle everywhere, always, in your mind. Everyone is your enemy, everyone is your friend. Every possible series of events is happening all at once. Live that way and nothing will surprise you. Everything that happens will be something that you’ve seen before.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;As I let my mind wander away from work for a bit today, I realized that this is a wonderful quote about science!&lt;/p&gt;
&lt;h3 id=&#34;fight-every-battle-everywhere-always-in-your-mind&#34;&gt;Fight every battle everywhere, always, in your mind&lt;/h3&gt;
&lt;p&gt;Baelish is a shrewd, obsessive planner. In planning for everything that could possibly happen, he always seems to be prepared, get what he wants, and stay alive. Just like staying alive in Westeros in positions of power, doing good science can be quite difficult because we are set adrift in extremely complex systems. There are so many paths that that can be followed to answer a research question (including the formulation of the question itself!), and all could be the subject of an intellectual battle with a critic. Studying the effect of yearly bonuses for teachers on long-term student outcomes? How do you define long-term? What outcomes will you measure and how? How will you prevent dropout? How do you make differing bonus amounts comparable for teachers who differ in terms of what they teach, where they live, what composition of students they teach from year to year? How would you even define &amp;ldquo;composition of students&amp;rdquo;? Also why study student outcomes as opposed to community outcomes? There is no way that a single study could address all of these concerns, or the ones that I couldn&amp;rsquo;t think of, but these concerns need to be thought about because they need to be &lt;em&gt;answered&lt;/em&gt; for us to have any hope of meaningful, actionable conclusions. Just the act of forecasting these hypothetical intellectual battles can motivate the design of better studies.&lt;/p&gt;
&lt;h3 id=&#34;everyone-is-your-enemy-everyone-is-your-friend&#34;&gt;Everyone is your enemy, everyone is your friend&lt;/h3&gt;
&lt;p&gt;Baelish is calculating and knows how effective people can be in various contexts. It can be helpful to think of everyone in the scientific community as your enemy—enemies ready to question every aspect of your work and find every possible hole—but only if it indeed motivates &lt;em&gt;you&lt;/em&gt; to do those very things. Only by heavily scrutinizing our own work can we make ourselves the best scientists possible. Acknowledging limitations in private and subsequently making them known to others is key to moving the state of knowledge forward. I do want to de-emphasize any paranoid or hateful connotations of this quote though! Some people in my field take the &amp;ldquo;everyone is your enemy&amp;rdquo; part too seriously and critique others in inflammatory ways.&lt;/p&gt;
&lt;p&gt;Now the friends part&amp;hellip;this probably works out better for science than for Baelish. Scientists form a community, and ideally &lt;a href=&#34;https://simplystatistics.org/2015/12/11/instead-of-research-on-reproducibility-just-do-reproducible-research/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;sharing everything&lt;/a&gt; about our work would facilitate a team effort to find even more limitations and address them fruitfully to get leaps and bounds closer to useful answers. But my impression is that things generally don&amp;rsquo;t happen this way. Groups work somewhat in isolation on different aspects of a problem. Perhaps consortia try to harmonize efforts in some respects, but useful information is still needed from external sources and not able to be integrated easily. Just as it is hard in Westeros to find good allies, it can be difficult in science to find good collaborators. But when it does happen, great deeds are in the works.&lt;/p&gt;
&lt;h3 id=&#34;every-possible-series-of-events-is-happening-all-at-once&#34;&gt;Every possible series of events is happening all at once&lt;/h3&gt;
&lt;p&gt;In Westeros, livelihoods dance on the whims of nobles and on the breath of armies that can be traded with coin coffers or decimated in an afternoon. This creates a palpable urgency for Baelish to always stay ahead of the game. This immediacy isn&amp;rsquo;t really felt in science. We don&amp;rsquo;t gamble with our lives when we submit a paper and wait for the review process to unfold. I think that the scientific community is lured to progress slowly with our &lt;a href=&#34;http://www.sciencemag.org/news/2015/12/got-just-single-observation-new-journal-will-publish-it&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;recognition system&lt;/a&gt; favoring large numbers of publications. Researchers who have large projects are incentivized to break the project up into several publications. I don&amp;rsquo;t think this is necessarily bad if the scientists have actually completed this larger body of research. The flaw I see is if it incentivizes scientists to publish work that isn&amp;rsquo;t as complete out of time pressure and fail to follow up with more complete validation because they feel the validation work isn&amp;rsquo;t &amp;ldquo;enough&amp;rdquo; for its own publication. There is &lt;a href=&#34;http://www.sciencemag.org/news/2016/02/if-you-fail-reproduce-another-scientist-s-results-journal-wants-know&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;some effort to recognize replication attempts&lt;/a&gt;, but I wish that there were more urgency and incentive to conduct more complete studies the first time around because it sets the baseline higher for future work.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Why statistics can be scary</title>
      <link>/post/why-statistics-can-be-scary/</link>
      <pubDate>Thu, 27 Mar 2014 02:52:57 +0000</pubDate>
      <guid>/post/why-statistics-can-be-scary/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;I’ve been planning for some time to start this blog mainly as a way to give intuition to people untrained in statistics about what statisticians do and why. For the last few weeks, I’ve been gathering ideas, and I’ve found that in the process I’ve had to be a lot more reflective about fundamental aims in statistics that I had almost started taking for granted. So as a brief aside, I highly encourage people to blog! Everyone cares about something, and blogging is a great way to (1) make sure you know your stuff, (2) learn stuff, and (3) share stuff. As a PhD student (1) and (2) are constantly among my worries, and I care about (3) because I love teaching and talking about ideas that are interesting to me.&lt;/p&gt;
&lt;p&gt;So let’s get to the interesting stuff (I hope)! I love statistics, but I know that most people do not feel the same way that I do. I know I can’t inspire a love of the field for everyone who reads this, but I do want to motivate statistics and offer some opinions as to why statistics tends to elicit grimaces from non-practitioners.&lt;/p&gt;
&lt;p&gt;As I was planning to start this blog, I asked my friends about their opinions about statistics, and it was pointed out that a particularly unsatisfying part of learning statistics is that students tend to get the feeling that they aren’t certain about anything. I won’t try to deny this because it’s completely true. But when are we ever 100% certain about anything &lt;strong&gt;interesting&lt;/strong&gt;? See if you can come up with an example of something that you know with absolute certainty and that actually raises your eyebrows. I’m coming up with “I will type the word ‘statistics’ at least one more time in this post” and “I will eat a brownie in the next week.” These are completely inevitable and therefore (to me) completely uninteresting statements. Even inevitabilities can have degrees of uncertainty when we pose them in a different way:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;“A new president will be elected next term.” But &lt;strong&gt;who&lt;/strong&gt; will win the election?&lt;/li&gt;
&lt;li&gt;“March Madness will come to an end soon.” But &lt;strong&gt;what team&lt;/strong&gt; will come out on top?&lt;/li&gt;
&lt;li&gt;“Another research paper in statistical genomics will be published in the next month.” But will it be any &lt;strong&gt;good&lt;/strong&gt;?&lt;/li&gt;
&lt;li&gt;“The government will spend money on scientific research next year.” But &lt;strong&gt;how much&lt;/strong&gt;?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The point is that although we are certain about the occurrence or non-occurrences of many events, we tend to be more interested in the &lt;strong&gt;details&lt;/strong&gt; surrounding these events, and these details are what give rise to uncertainty. Statistics cannot change this inherent uncertainty in the world but it can give us a tool to make more informed predictions. For example, if I were trying to find the best place to buy gas in my neighborhood, I could look at the daily history of prices per gallon at all of the local stations and do a statistical analysis to determine which station tends to be the cheapest. Statistics will not allow me to be certain of the price per gallon at these stations tomorrow. The only way I could know this with certainty is if I had infinite and perfect knowledge of how gas prices are determined each day. This would entail knowing everything about the workings of the economy and the mindsets of CEOs of gas companies among many other things. But I don’t have this infinite knowledge. I have to work with the limited data available to me, and statistics is a structured framework for doing so.&lt;/p&gt;
&lt;p&gt;The structure in statistics is in large part governed by models. Model specification is a core part of statistics, and I contend that it is also what makes our field so scary. Models can be useful because they allow us to propose reasons for why we observe what we do in a concrete, structured, and reproducible way. I’ll illustrate this with an example.&lt;/p&gt;
&lt;p&gt;Suppose you work at a company that does a weekly lottery for a gift certificate to a local restaurant. Each week, a computer randomly selects one of the 500 total employees to receive the prize so that each of the 500 employees has an equal chance of being picked (1 in 500). For many, intuition says, “I should have a higher chance of being selected as the weeks go by.” This is not a correct statement, but it is an easy mistake to make if you are not thinking about the mathematics behind the statement. This is why models can be useful. They can help us translate statements like these into mathematical expressions that precisely quantify the probabilities we are trying to calculate. This lottery is exactly an example of what statisticians would call a “binomial experiment.” It is a model that allows us to calculate the probability of different numbers of successes in a series of independent trials and allows us to supply the (fixed) probability of success, the number of trials, and the number of successes. So in this situation, the fixed probability of success is 1/500, the number of trials is the number of weeks the lottery has been taking place, and the number of successes of interest is zero because we are interested in the probability of never being picked in a given number of weeks.&lt;/p&gt;
&lt;p&gt;The statement “I should have a higher chance of being selected as the weeks go by” translates to the question “What is the probability that I am chosen in week X?” and is a question that is easily answerable by our model of the lottery. Because our model requires a fixed probability of success (1/500), the probability of being chosen in week X is 1/500 &lt;strong&gt;regardless of what week it is&lt;/strong&gt;. More intuitively, why is this so? Our question is one about the characteristics of the &lt;strong&gt;lottery&lt;/strong&gt;, which is a fixed procedure. We can’t change the fact that there are 500 employees, and we can’t change the computer that is picking between the 500 employees equally.&lt;/p&gt;
&lt;p&gt;However, by keeping in mind that our model of the lottery allows us to calculate probabilities of numbers of successes, we should instead ask, “What is the probability that I am chosen exactly zero times in X weeks?” which translates to the intuition “It should be increasing unlikely for me to never be picked in all the weeks the lottery has been going on.” This question concerns the outcome of the lottery, which is uncertain, whereas we had previously been inquiring about a characteristic of the lottery design, which was quite certain. Our model easily answers this question, and the probabilities as a function of the number of weeks X are shown in the graph on the left below. The probabilities for the complementary question “What is the probability that I am chosen at least once in X weeks?” are shown below on the right. (The R code for making the plots is also shown below.)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p &amp;lt;- 1/500
weeks &amp;lt;- 1:500
prob_notchosen &amp;lt;- (1-p)^weeks
prob_chosen &amp;lt;- 1-prob_notchosen
par(mfrow = c(1,2), mar = c(4,4,2,1), bty = &amp;quot;l&amp;quot;)
plot(weeks, prob_notchosen, xlab = &amp;quot;Week&amp;quot;, ylab = &amp;quot;Probability&amp;quot;, main = &amp;quot;Never being chosen&amp;quot;, type = &amp;quot;l&amp;quot;, ylim = c(0,1))
plot(weeks, prob_chosen, xlab = &amp;quot;Week&amp;quot;, ylab = &amp;quot;Probability&amp;quot;, main = &amp;quot;Chosen at least once&amp;quot;, type = &amp;quot;l&amp;quot;, ylim = c(0,1))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2014-03-27-why-statistics-can-be-scary_files/figure-html/lottery-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can see that as weeks go by, the probability of never once being chosen declines, and the complementary probability of being chosen at least once increases. So the initial intuition “I should have a higher chance of being selected as the weeks go by” is wrong because we did not carefully form our question. What we really wanted to express is the increasing probability of being picked at least once in a larger and larger time frame. And this was a lot easier to express once we had cast the lottery as a binomial model and determined the types of questions that our model was suited to answer.&lt;/p&gt;
&lt;p&gt;In this example of the lottery, the binomial model was an exact description of the situation. But very rarely in real life are the situations we want to study so clear cut. Most of the time interesting systems are complex, and statisticians have to make many simplifying assumptions in order to even begin the modeling process. The oft-quoted line from George Box illustrates this situation “Essentially, all models are wrong, but some are useful.” The “some are useful” part of Box’s quote is what can make statistics so scary. How can we know whether our models are really useful? In other words, how can we know whether our models still closely approximate reality? We tend to fall in love with our models because we invest so much time in them, and this is partly why our collaborators in non-statistical fields find our process mystifying. We often adopt models because they &lt;strong&gt;seem&lt;/strong&gt; to fit reality well enough and mostly because they are convenient. But in order to make meaningful discoveries, we can’t just guess and assume that our reasoning alone justifies the models we create. We either need to do a better job at incorporating the extensive knowledge of field-specific experts into our models or restrain the urge to take the modeling approach altogether.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
